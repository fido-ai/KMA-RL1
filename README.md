# KMA-RL1

Based on the [CS-234 course](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

## Lecute 1 - Introduction to Reinforcement Learning

### Additional Materials
- High level introduction: SB chapter 1
- Linear algebra review
- Probability review
- [Python tutorial](https://cs231n.github.io/python-numpy-tutorial/)

### Lecture discussion
- [gym env](https://www.gymlibrary.dev)
- [saple factory](https://github.com/alex-petrenko/sample-factory) 

## Lecture 2 - Tabular MDP planning
- SB chapter 3, 4.1-4.4

## Lecture 3 - Tabular RL policy evaluation
- SB chapter 5.1, 5.5, 6.1-6.3
- [David Silver's Lecture 4](https://www.davidsilver.uk/teaching/)

## Lecture 4 - Q-learning
- SB chapter 5.2, 5.4, 6.4-6.5, 6.7

## Lecture (4, 5) - RL with function approximation
- SB chapter 9.3, 9.6, 9.7

## Lecture (7, 8) - Policy Search 
- SB chapter 13


</br>
</br>
</br>

## Practical part

### Practice-related
- [RL specialization](https://github.com/ChanchalKumarMaji/Reinforcement-Learning-Specialization)
- [detailed practical materials](https://github.com/dennybritz/reinforcement-learning)
- [previous-year assignemnts & solutions](https://github.com/righteousronin/Portfolio/tree/main/Reinforcement%20Learning)
- [gymnasium gym deep-dive repo](https://github.com/WhatIThinkAbout/BabyRobotGym)
- [gym setup article](https://towardsdatascience.com/creating-a-custom-gym-environment-for-jupyter-notebooks-e17024474617)

### Recordings
- [practice-01](https://youtu.be/897q4tPmsGg)
- [practice-02](https://youtu.be/-dWOD5SBgfs)
- [practice-03](https://youtu.be/qhib3DFOEpY)

</br>
</br>
</br>

# Homeworks

## Homework 1
Submission [link](https://forms.gle/QzL7sAmMEgUeYxx57) </br>
First deadline: 6/03/22 (30 points max)</br>
Second deadline: 13/03/22 (25 points max)</br>
Final deadline: 24/04/22 (20 points max)</br>

## Homework 2
Submission link (released soon)</br>
First deadline: </br>
Second deadline:</br>
Final deadline: 24/04/22 (50%)</br>

</br>
</br>


# List of papers
- 13/04/22  [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/abs/1312.5602)

- [SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards](https://arxiv.org/abs/1905.11108)
- [Augmented Q Imitation Learning (AQIL)](https://arxiv.org/abs/2004.00993)
- [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)
- [AdaFrame: Adaptive Frame Selection for Fast Video Recognition](https://arxiv.org/abs/1811.12432); [Adaptive Focus for Efficient Video Recognition](https://arxiv.org/pdf/2105.03245.pdf); [AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition](https://arxiv.org/pdf/2112.14238.pdf)
- [Benchmarking Reinforcement Learning Algorithms on Real-World Robots](https://arxiv.org/abs/1809.07731)
- [Generative Adversarial Imitation Learning](https://arxiv.org/abs/1606.03476)
- [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)
